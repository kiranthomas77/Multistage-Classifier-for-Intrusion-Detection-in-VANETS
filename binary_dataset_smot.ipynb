{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db76d57a-610b-4ea5-94bd-80ce9baf4e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2821051, 42)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the dataset from the pickle file\n",
    "with open('processed/binary_dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_scaled = data['features']  # Features\n",
    "y_binary = data['labels']    # Labels\n",
    "X_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b44e53b-473e-4123-b86d-a52835a0aee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 2273097 samples\n",
      "Class 1: 547954 samples\n",
      "   Class    Count\n",
      "0      0  2273097\n",
      "1      1   547954\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'y_binary' is a numpy array or list containing binary labels (0s and 1s)\n",
    "# Count the occurrences of each class\n",
    "unique_classes, class_counts = np.unique(y_binary, return_counts=True)\n",
    "\n",
    "# Print the class distribution\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    print(f\"Class {cls}: {count} samples\")\n",
    "\n",
    "# Alternatively, you can display the class distribution using a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "class_distribution = pd.DataFrame({'Class': unique_classes, 'Count': class_counts})\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f97c33",
   "metadata": {},
   "source": [
    "OVERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a34f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "Counter({0: 2273097, 1: 547954})\n",
      "Class distribution after SMOTE:\n",
      "Counter({0: 2273097, 1: 2273097})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "#USE RANDOM SAMPLING INSTEAD ?\n",
    "\n",
    "\n",
    "# Assuming 'X_scaled' and 'y_binary' are your feature matrix and binary labels\n",
    "# Check the class distribution before applying SMOTE\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(Counter(y_binary))\n",
    "\n",
    "# Define the sampling strategy for SMOTE\n",
    "# Set 'sampling_strategy' to 'auto' or a specific ratio to balance the classes\n",
    "sampling_strategy = 'auto'  # Use 'auto' to balance the classes\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy)\n",
    "\n",
    "# Apply SMOTE to the dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_binary)\n",
    "\n",
    "# Check the class distribution after applying SMOTE\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(Counter(y_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51631774",
   "metadata": {},
   "source": [
    "UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821c595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before undersampling:\n",
      "Counter({0: 2273097, 1: 547954})\n",
      "Class distribution after undersampling:\n",
      "Counter({0: 547954, 1: 547954})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming 'X_scaled' and 'y_binary' are your feature matrix and binary labels\n",
    "# Check the class distribution before applying undersampling\n",
    "print(\"Class distribution before undersampling:\")\n",
    "print(Counter(y_binary))\n",
    "\n",
    "# Initialize RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply RandomUnderSampler to the dataset\n",
    "X_resampled, y_resampled = rus.fit_resample(X_scaled, y_binary)\n",
    "\n",
    "# Check the class distribution after applying RandomUnderSampler\n",
    "print(\"Class distribution after undersampling:\")\n",
    "print(Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c86edf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4546194, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4ecd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset saved to processed/oversampled_balanced_binary_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the resampled dataset using pickle\n",
    "resampled_dataset = {'features': X_resampled, 'labels': y_resampled}\n",
    "\n",
    "# Define the filename for the saved dataset\n",
    "output_filename = 'processed/oversampled_balanced_binary_dataset.pkl'\n",
    "\n",
    "# Open a file in binary write mode and save the dataset using pickle.dump()\n",
    "with open(output_filename, 'wb') as f:\n",
    "    pickle.dump(resampled_dataset, f)\n",
    "\n",
    "print(f\"Resampled dataset saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d238407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled dataset saved to processed/undersampled_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert resampled features (X_resampled) and labels (y_resampled) to pandas DataFrames\n",
    "X_resampled_df = pd.DataFrame(X_resampled, columns=data['features'].columns)  # Assuming column names are available in the loaded data\n",
    "y_resampled_series = pd.Series(y_resampled, name='Label')\n",
    "\n",
    "# Concatenate features and labels into a single DataFrame\n",
    "resampled_df = pd.concat([X_resampled_df, y_resampled_series], axis=1)\n",
    "\n",
    "# Define the filename for the saved undersampled dataset\n",
    "output_filename = 'processed/undersampled_dataset.csv'\n",
    "\n",
    "# Save the undersampled dataset to CSV\n",
    "resampled_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Undersampled dataset saved to {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
